{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05623ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1002\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  const force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "const JS_MIME_TYPE = 'application/javascript';\n",
       "  const HTML_MIME_TYPE = 'text/html';\n",
       "  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  const CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    const script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    const cell = handle.cell;\n",
       "\n",
       "    const id = cell.output_area._bokeh_element_id;\n",
       "    const server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd_clean, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            const id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd_destroy);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    const output_area = handle.output_area;\n",
       "    const output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      const bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      const script_attrs = bk_div.children[0].attributes;\n",
       "      for (let i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      const toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    const events = require('base/js/events');\n",
       "    const OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  const NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    const el = document.getElementById(\"1002\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.3.min.js\"];\n",
       "  const css_urls = [];\n",
       "\n",
       "  const inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "          for (let i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      const cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"1002\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.3.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n          for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\nif (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from typing import Optional\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "from bilby.core.prior import Constraint, Cosine, PriorDict, Uniform\n",
    "from bilby.gw.conversion import convert_to_lal_binary_black_hole_parameters\n",
    "from bilby.gw.prior import UniformSourceFrame\n",
    "from bilby.gw.source import lal_binary_black_hole\n",
    "from bilby.gw.waveform_generator import WaveformGenerator\n",
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.palettes import Dark2_8 as palette\n",
    "from bokeh.plotting import figure\n",
    "from gwpy.signal.filter_design import fir_from_transfer\n",
    "from gwpy.timeseries import TimeSeries\n",
    "from rich.progress import track\n",
    "\n",
    "from ml4gw.dataloading import InMemoryDataset\n",
    "from ml4gw.distributions import Cosine as CosineSampler\n",
    "from ml4gw.distributions import LogNormal as LogNormalSampler\n",
    "from ml4gw.distributions import Uniform as UniformSampler\n",
    "from ml4gw.transforms import RandomWaveformInjection\n",
    "\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32217acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data parameters\n",
    "START = 1262607622\n",
    "DURATION = 12288\n",
    "SAMPLE_RATE = 2048\n",
    "KERNEL_LENGTH = 2\n",
    "HIGHPASS = 20\n",
    "\n",
    "# Injection parameters\n",
    "WAVEFORM_DURATION = 8\n",
    "NUM_WAVEFORMS = 20000\n",
    "REFERENCE_FREQUENCY = 50\n",
    "MINIMUM_FREQUENCY = 20\n",
    "INJECTION_FRACTION = 0.5\n",
    "MEAN_SNR = 15\n",
    "STD_SNR = 15\n",
    "MIN_SNR = 1\n",
    "\n",
    "# Optimization parameters\n",
    "VALID_FRAC = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "112e77d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "background = []\n",
    "for ifo in \"HL\":\n",
    "    ts = TimeSeries.fetch_open_data(\n",
    "        f\"{ifo}1\", start=START, end=START + DURATION\n",
    "    )\n",
    "    ts = ts.resample(SAMPLE_RATE)\n",
    "    background.append(ts.value)\n",
    "background = np.stack(background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b62a9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_length = int((1 - VALID_FRAC) * SAMPLE_RATE * DURATION)\n",
    "train_background, valid_background = np.split(\n",
    "    background, [train_length], axis=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10456c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_dict = PriorDict(\n",
    "    dict(\n",
    "        mass_1=Uniform(\n",
    "            name=\"mass_1\", minimum=5, maximum=100, unit=r\"$M_{\\odot}$\"\n",
    "        ),\n",
    "        mass_2=Uniform(\n",
    "            name=\"mass_2\", minimum=5, maximum=100, unit=r\"$M_{\\odot}$\"\n",
    "        ),\n",
    "        mass_ratio=Constraint(name=\"mass_ratio\", minimum=0.2, maximum=5.0),\n",
    "        luminosity_distance=UniformSourceFrame(\n",
    "            name=\"luminosity_distance\", minimum=100, maximum=3000, unit=\"Mpc\"\n",
    "        ),\n",
    "        dec=Cosine(name=\"dec\"),\n",
    "        ra=Uniform(\n",
    "            name=\"ra\", minimum=0, maximum=2 * np.pi, boundary=\"periodic\"\n",
    "        ),\n",
    "        theta_jn=0,\n",
    "        psi=0,\n",
    "        phase=0,\n",
    "        a_1=0,\n",
    "        a_2=0,\n",
    "        tilt_1=0,\n",
    "        tilt_2=0,\n",
    "        phi_12=0,\n",
    "        phi_jl=0,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3983617e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:17 bilby INFO    : Waveform generator initiated with\n",
      "  frequency_domain_source_model: bilby.gw.source.lal_binary_black_hole\n",
      "  time_domain_source_model: None\n",
      "  parameter_conversion: bilby.gw.conversion.convert_to_lal_binary_black_hole_parameters\n"
     ]
    }
   ],
   "source": [
    "waveform_generator = WaveformGenerator(\n",
    "    duration=WAVEFORM_DURATION,\n",
    "    sampling_frequency=SAMPLE_RATE,\n",
    "    frequency_domain_source_model=lal_binary_black_hole,\n",
    "    parameter_conversion=convert_to_lal_binary_black_hole_parameters,\n",
    "    waveform_arguments={\n",
    "        \"waveform_approximant\": \"IMRPhenomPv2\",\n",
    "        \"reference_frequency\": REFERENCE_FREQUENCY,\n",
    "        \"minimum_frequency\": MINIMUM_FREQUENCY,\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "def generate_waveform(i):\n",
    "    row = {k: v[i] for k, v in params.items()}\n",
    "    polarizations = waveform_generator.time_domain_strain(row)\n",
    "    polarization_names = sorted(polarizations.keys())\n",
    "    polarizations = np.stack([polarizations[p] for p in polarization_names])\n",
    "\n",
    "    # center so that coalescence time is middle sample\n",
    "    dt = WAVEFORM_DURATION / 2\n",
    "    polarizations = np.roll(polarizations, int(dt * SAMPLE_RATE), axis=-1)\n",
    "    return polarizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c50c27",
   "metadata": {},
   "source": [
    "The process of actually generating these waveforms can be pretty time consuming, so we'll create a cache file for skipping it on repeated runs. We'll also use multiple threads in case the cache file doesn't exist so that we're not waiting around too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1effda5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": [
       "\u001b[?25l"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea9a7d1ab29a436d8c703672626a1f3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[?25h"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ThreadPoolExecutor(\u001b[38;5;241m4\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[1;32m     12\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28menumerate\u001b[39m(pool\u001b[38;5;241m.\u001b[39mmap(generate_waveform, \u001b[38;5;28mrange\u001b[39m(NUM_WAVEFORMS)))\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, polarizations \u001b[38;5;129;01min\u001b[39;00m track(it, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerating waveforms\u001b[39m\u001b[38;5;124m\"\u001b[39m, total\u001b[38;5;241m=\u001b[39mNUM_WAVEFORMS):\n\u001b[1;32m     14\u001b[0m         waveforms[i] \u001b[38;5;241m=\u001b[39m polarizations\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m h5py\u001b[38;5;241m.\u001b[39mFile(WAVEFORMS_FILE, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4gw-examples/lib/python3.10/site-packages/rich/progress.py:168\u001b[0m, in \u001b[0;36mtrack\u001b[0;34m(sequence, description, total, auto_refresh, console, transient, get_time, refresh_per_second, style, complete_style, finished_style, pulse_style, update_period, disable, show_speed)\u001b[0m\n\u001b[1;32m    157\u001b[0m progress \u001b[38;5;241m=\u001b[39m Progress(\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;241m*\u001b[39mcolumns,\n\u001b[1;32m    159\u001b[0m     auto_refresh\u001b[38;5;241m=\u001b[39mauto_refresh,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    164\u001b[0m     disable\u001b[38;5;241m=\u001b[39mdisable,\n\u001b[1;32m    165\u001b[0m )\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m progress:\n\u001b[0;32m--> 168\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m progress\u001b[38;5;241m.\u001b[39mtrack(\n\u001b[1;32m    169\u001b[0m         sequence, total\u001b[38;5;241m=\u001b[39mtotal, description\u001b[38;5;241m=\u001b[39mdescription, update_period\u001b[38;5;241m=\u001b[39mupdate_period\n\u001b[1;32m    170\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4gw-examples/lib/python3.10/site-packages/rich/progress.py:1210\u001b[0m, in \u001b[0;36mProgress.track\u001b[0;34m(self, sequence, total, task_id, description, update_period)\u001b[0m\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlive\u001b[38;5;241m.\u001b[39mauto_refresh:\n\u001b[1;32m   1209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _TrackThread(\u001b[38;5;28mself\u001b[39m, task_id, update_period) \u001b[38;5;28;01mas\u001b[39;00m track_thread:\n\u001b[0;32m-> 1210\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m sequence:\n\u001b[1;32m   1211\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m value\n\u001b[1;32m   1212\u001b[0m             track_thread\u001b[38;5;241m.\u001b[39mcompleted \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4gw-examples/lib/python3.10/concurrent/futures/_base.py:621\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[1;32m    619\u001b[0m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 621\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_result_or_cancel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    623\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs\u001b[38;5;241m.\u001b[39mpop(), end_time \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic())\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4gw-examples/lib/python3.10/concurrent/futures/_base.py:319\u001b[0m, in \u001b[0;36m_result_or_cancel\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 319\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    321\u001b[0m         fut\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4gw-examples/lib/python3.10/concurrent/futures/_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4gw-examples/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "WAVEFORMS_FILE = \"waveforms.h5\"\n",
    "if os.path.exists(WAVEFORMS_FILE):\n",
    "    print(\"Using local cache file\")\n",
    "    with h5py.File(WAVEFORMS_FILE, \"r\") as f:\n",
    "        polarizations = [f[p][:][:, None] for p in [\"cross\", \"plus\"]]\n",
    "        waveforms = np.concatenate(polarizations, axis=1)\n",
    "        params = {k: v[:] for k, v in f[\"params\"].items()}\n",
    "else:\n",
    "    waveforms = np.zeros(\n",
    "        (NUM_WAVEFORMS, 2, int(SAMPLE_RATE * WAVEFORM_DURATION))\n",
    "    )\n",
    "    params = prior_dict.sample(NUM_WAVEFORMS)\n",
    "    with ThreadPoolExecutor(4) as pool:\n",
    "        it = enumerate(pool.map(generate_waveform, range(NUM_WAVEFORMS)))\n",
    "        for i, polarizations in track(\n",
    "            it, \"Generating waveforms\", total=NUM_WAVEFORMS\n",
    "        ):\n",
    "            waveforms[i] = polarizations\n",
    "\n",
    "    with h5py.File(WAVEFORMS_FILE, \"w\") as f:\n",
    "        f[\"cross\"] = waveforms[:, 0]\n",
    "        f[\"plus\"] = waveforms[:, 1]\n",
    "        params_group = f.create_group(\"params\")\n",
    "        for p, values in params.items():\n",
    "            params_group[p] = values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e17e453",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.arange(0, WAVEFORM_DURATION, 1 / SAMPLE_RATE) - WAVEFORM_DURATION / 2\n",
    "p = figure(\n",
    "    width=750,\n",
    "    height=300,\n",
    "    x_axis_label=\"Time from coalescence [s]\",\n",
    "    y_axis_label=\"Gravitational wave strain [unitless]\",\n",
    "    tools=\"\",\n",
    ")\n",
    "for i in range(2):\n",
    "    p.line(\n",
    "        t,\n",
    "        waveforms[1, i],\n",
    "        line_color=palette[i],\n",
    "        line_alpha=0.8,\n",
    "        line_width=1.5,\n",
    "        legend_label=[\"cross\", \"plus\"][i],\n",
    "    )\n",
    "p.legend.click_policy = \"hide\"\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a61bf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = int((1 - VALID_FRAC) * NUM_WAVEFORMS)\n",
    "train_waveforms, valid_waveforms = np.split(waveforms, [num_train], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924b24d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = InMemoryDataset(\n",
    "    train_background,\n",
    "    kernel_size=int(KERNEL_LENGTH * SAMPLE_RATE),\n",
    "    batch_size=256,\n",
    "    coincident=False,\n",
    "    shuffle=True,\n",
    "    batches_per_epoch=100,\n",
    ")\n",
    "valid_loader = InMemoryDataset(\n",
    "    valid_background,\n",
    "    kernel_size=int(KERNEL_LENGTH * SAMPLE_RATE),\n",
    "    batch_size=1024,\n",
    "    coincident=True,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec597fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "injector = RandomWaveformInjection(\n",
    "    sample_rate=SAMPLE_RATE,\n",
    "    ifos=[\"H1\", \"L1\"],\n",
    "    dec=CosineSampler(),\n",
    "    psi=UniformSampler(0, np.pi),\n",
    "    phi=UniformSampler(-np.pi, np.pi),\n",
    "    snr=LogNormalSampler(MEAN_SNR, STD_SNR, MIN_SNR),\n",
    "    highpass=HIGHPASS,\n",
    "    prob=INJECTION_FRACTION,\n",
    "    trigger_offset=0.5,\n",
    "    plus=train_waveforms[:, 1],\n",
    "    cross=train_waveforms[:, 0],\n",
    ")\n",
    "injector.fit(H1=train_background[0], L1=train_background[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7713fa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform, sampled_params = injector.sample(1)\n",
    "dec, psi, phi, snr = sampled_params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac117566",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WhiteningTransform(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_ifos: int,\n",
    "        sample_rate: float,\n",
    "        kernel_length: float,\n",
    "        fftlength: float = 2,\n",
    "        highpass: Optional[float] = None,\n",
    "        fduration: Optional[float] = None,\n",
    "    ) -> None:\n",
    "        \"\"\"Torch module for performing whitening. The first and last\n",
    "        (fduration / 2) seconds of data are corrupted by the whitening\n",
    "        and will be cropped. Thus, the output length\n",
    "        that is ultimately passed to the network will be\n",
    "        (kernel_length - fduration)\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        self.num_ifos = num_ifos\n",
    "        self.sample_rate = sample_rate\n",
    "        self.kernel_length = kernel_length\n",
    "        self.fftlength = fftlength\n",
    "\n",
    "        self.df = 1 / kernel_length\n",
    "        self.ncorner = int(highpass / self.df) if highpass else 0\n",
    "        self.fduration = fduration or kernel_length / 2\n",
    "\n",
    "        # number of samples of corrupted data\n",
    "        # due to settling in of whitening filter\n",
    "        self.crop_samples = int((self.fduration / 2) * self.sample_rate)\n",
    "        self.ntaps = int(self.fduration * self.sample_rate)\n",
    "        self.pad = (self.ntaps - 1) // 2\n",
    "        self.kernel_size = int(kernel_length * sample_rate)\n",
    "\n",
    "        # initialize the parameter with 0s, then fill it out later\n",
    "        tdf = torch.zeros((num_ifos, 1, self.ntaps - 1))\n",
    "        self.register_buffer(\"time_domain_filter\", tdf)\n",
    "\n",
    "        window = torch.hann_window(self.ntaps)\n",
    "        self.register_buffer(\"window\", window, persistent=False)\n",
    "\n",
    "    def fit(self, **ifos: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Build a whitening time domain filter\n",
    "        \"\"\"\n",
    "        if len(ifos) != self.num_ifos:\n",
    "            raise ValueError(\n",
    "                \"Expected to fit whitening transform on {} backgrounds, \"\n",
    "                \"but was passed {}\".format(self.num_ifos, len(ifos))\n",
    "            )\n",
    "\n",
    "        tdfs = []\n",
    "        for x in ifos.values():\n",
    "            ts = TimeSeries(x, dt=1 / self.sample_rate)\n",
    "            asd = ts.asd(\n",
    "                fftlength=self.fftlength, window=\"hann\", method=\"median\"\n",
    "            )\n",
    "            asd = asd.interpolate(self.df).value\n",
    "            if (asd == 0).any():\n",
    "                raise ValueError(\"Found 0 values in background asd\")\n",
    "\n",
    "            tdf = fir_from_transfer(\n",
    "                1 / asd,\n",
    "                ntaps=self.ntaps,\n",
    "                window=\"hann\",\n",
    "                ncorner=self.ncorner,\n",
    "            )\n",
    "            tdfs.append(tdf)\n",
    "\n",
    "        tdf = torch.tensor(np.stack(tdfs)[:, None, :-1], dtype=torch.float64)\n",
    "        self.time_domain_filter.copy_(tdf)\n",
    "\n",
    "    def forward(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        # do a constant detrend along the time axis,\n",
    "        X = X - X.mean(axis=-1, keepdims=True)\n",
    "        X[:, :, : self.pad] *= self.window[: self.pad]\n",
    "        X[:, :, -self.pad :] *= self.window[-self.pad :]\n",
    "\n",
    "        nfft = min(8 * self.time_domain_filter.size(-1), self.kernel_size)\n",
    "        if nfft >= self.kernel_size / 2:\n",
    "            conv = torch.nn.functional.conv1d(\n",
    "                X,\n",
    "                self.time_domain_filter,\n",
    "                groups=self.num_ifos,\n",
    "                padding=int(self.pad),\n",
    "            )\n",
    "\n",
    "            # crop the beginning and ending fduration / 2\n",
    "            conv = conv[:, :, self.crop_samples : -self.crop_samples]\n",
    "        else:\n",
    "            raise NotImplementedError(\n",
    "                \"An optimal torch implementation of whitening for short \"\n",
    "                \"fdurations is not complete. Use a larger fduration \"\n",
    "            )\n",
    "        # scale by sqrt(2 / sample_rate) for some inscrutable\n",
    "        # signal processing reason beyond my understanding\n",
    "        return conv * (2 / self.sample_rate) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5d9a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = WhiteningTransform(\n",
    "    num_ifos=2,\n",
    "    sample_rate=SAMPLE_RATE,\n",
    "    kernel_length=KERNEL_LENGTH,\n",
    "    highpass=HIGHPASS,\n",
    ")\n",
    "preprocessor.fit(H1=train_background[0], L1=train_background[1])\n",
    "preprocessor.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c1cb7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
